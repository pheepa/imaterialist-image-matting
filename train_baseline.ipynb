{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This kernel is U-Net Baseline written by PyTorch\n",
    "In this kernel, there are many places that are simplified now.  \n",
    "So, you should fix these bad points.  \n",
    "\n",
    "[U-Net web site](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/)  \n",
    "[U-Net paper](https://arxiv.org/abs/1505.04597)  \n",
    "\n",
    "I reference [this blog post](https://lp-tech.net/articles/hzfn7?page=2  ) in U-Net installation.  \n",
    "Thank you awesome this blog post.  \n",
    "\n",
    "This is [my EDA](https://www.kaggle.com/go1dfish/fgvc6-simple-eda).  \n",
    "If you don't know this competition rule and data, this EDA might help you.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['label_descriptions.json', 'train.csv', 'train', 'test', 'sample_submission.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "print(os.listdir(\"input\"))\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"input/\"\n",
    "train_img_dir = input_dir + \"train/\"\n",
    "test_img_dir = input_dir + \"test/\"\n",
    "\n",
    "WIDTH = 224\n",
    "HEIGHT = 224\n",
    "category_num = 1 + 1\n",
    "\n",
    "ratio = 8\n",
    "\n",
    "epoch_num = 4\n",
    "batch_size = 8\n",
    "\n",
    "device = \"cuda:0\"\n",
    "# device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45196"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(\"input/train/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3194"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(\"input/test/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "      <th>ClassId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000663ed1ff0c4e0132b9b9ac53f6e.jpg</td>\n",
       "      <td>6068157 7 6073371 20 6078584 34 6083797 48 608...</td>\n",
       "      <td>5214</td>\n",
       "      <td>3676</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000663ed1ff0c4e0132b9b9ac53f6e.jpg</td>\n",
       "      <td>6323163 11 6328356 32 6333549 53 6338742 75 63...</td>\n",
       "      <td>5214</td>\n",
       "      <td>3676</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000663ed1ff0c4e0132b9b9ac53f6e.jpg</td>\n",
       "      <td>8521389 10 8526585 30 8531789 42 8537002 46 85...</td>\n",
       "      <td>5214</td>\n",
       "      <td>3676</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000663ed1ff0c4e0132b9b9ac53f6e.jpg</td>\n",
       "      <td>12903854 2 12909064 7 12914275 10 12919485 15 ...</td>\n",
       "      <td>5214</td>\n",
       "      <td>3676</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000663ed1ff0c4e0132b9b9ac53f6e.jpg</td>\n",
       "      <td>10837337 5 10842542 14 10847746 24 10852951 33...</td>\n",
       "      <td>5214</td>\n",
       "      <td>3676</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                ImageId  \\\n",
       "0  00000663ed1ff0c4e0132b9b9ac53f6e.jpg   \n",
       "1  00000663ed1ff0c4e0132b9b9ac53f6e.jpg   \n",
       "2  00000663ed1ff0c4e0132b9b9ac53f6e.jpg   \n",
       "3  00000663ed1ff0c4e0132b9b9ac53f6e.jpg   \n",
       "4  00000663ed1ff0c4e0132b9b9ac53f6e.jpg   \n",
       "\n",
       "                                       EncodedPixels  Height  Width ClassId  \n",
       "0  6068157 7 6073371 20 6078584 34 6083797 48 608...    5214   3676       6  \n",
       "1  6323163 11 6328356 32 6333549 53 6338742 75 63...    5214   3676       0  \n",
       "2  8521389 10 8526585 30 8531789 42 8537002 46 85...    5214   3676      28  \n",
       "3  12903854 2 12909064 7 12914275 10 12919485 15 ...    5214   3676      31  \n",
       "4  10837337 5 10842542 14 10847746 24 10852951 33...    5214   3676      32  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(input_dir + \"train.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['ClassId'][train_df['ClassId'] == 46] = 0\n",
    "# train_df['ClassId'][train_df['ClassId'] != 46] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "source": [
    "# Define utils\n",
    "For suniqueicity, It focus only category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_onehot_vec(x):\n",
    "    vec = np.zeros(category_num)\n",
    "    vec[x] = 1\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mask_img(segment_df):\n",
    "    seg_width = segment_df.at[0, \"Width\"]\n",
    "    seg_height = segment_df.at[0, \"Height\"]\n",
    "    seg_img = np.full(seg_width*seg_height, category_num-1, dtype=np.int32)\n",
    "    for encoded_pixels, class_id in zip(segment_df[\"EncodedPixels\"].values, segment_df[\"ClassId\"].values):\n",
    "        pixel_list = list(map(int, encoded_pixels.split(\" \")))\n",
    "        for i in range(0, len(pixel_list), 2):\n",
    "            start_index = pixel_list[i] - 1\n",
    "            index_len = pixel_list[i+1] - 1\n",
    "            seg_img[start_index:start_index+index_len] = int(class_id.split(\"_\")[0])\n",
    "    seg_img = seg_img.reshape((seg_height, seg_width), order='F')\n",
    "    seg_img = cv2.resize(seg_img, (WIDTH, HEIGHT), interpolation=cv2.INTER_NEAREST)\n",
    "    \"\"\"\n",
    "    seg_img_onehot = np.zeros((HEIGHT, WIDTH, category_num), dtype=np.int32)\n",
    "    #seg_img_onehot = np.zeros((seg_height//ratio, seg_width//ratio, category_num), dtype=np.int32)\n",
    "    # OPTIMIZE: slow\n",
    "    for ind in range(HEIGHT):\n",
    "        for col in range(WIDTH):\n",
    "            seg_img_onehot[ind, col] = make_onehot_vec(seg_img[ind, col])\n",
    "    \"\"\"\n",
    "    return seg_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(df, batch_size):\n",
    "    img_ind_num = df.groupby(\"ImageId\")[\"ClassId\"].count()\n",
    "    index = df.index.values[0]\n",
    "    trn_images = []\n",
    "    seg_images = []\n",
    "    for i, (img_name, ind_num) in enumerate(img_ind_num.items()):\n",
    "        img = cv2.imread(train_img_dir + img_name)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        img = cv2.resize(img, (WIDTH, HEIGHT), interpolation=cv2.INTER_AREA)\n",
    "        segment_df = (df.loc[index:index+ind_num-1, :]).reset_index(drop=True)\n",
    "        index += ind_num\n",
    "        if segment_df[\"ImageId\"].nunique() != 1:\n",
    "            raise Exception(\"Index Range Error\")\n",
    "        seg_img = make_mask_img(segment_df)\n",
    "        \n",
    "        # HWC -> CHW\n",
    "        img = img.transpose((2, 0, 1))\n",
    "        #seg_img = seg_img.transpose((2, 0, 1))\n",
    "        \n",
    "        trn_images.append(img)\n",
    "        seg_images.append(seg_img)\n",
    "        if((i+1) % batch_size == 0):\n",
    "            yield np.array(trn_images, dtype=np.float32) / 255, np.array(seg_images, dtype=np.int32)\n",
    "            trn_images = []\n",
    "            seg_images = []\n",
    "    if(len(trn_images) != 0):\n",
    "        yield np.array(trn_images, dtype=np.float32) / 255, np.array(seg_images, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_generator(df):\n",
    "    img_names = df[\"ImageId\"].values\n",
    "    for img_name in img_names:\n",
    "        img = cv2.imread(test_img_dir + img_name)\n",
    "        img = cv2.resize(img, (WIDTH, HEIGHT), interpolation=cv2.INTER_AREA)\n",
    "        # HWC -> CHW\n",
    "        img = img.transpose((2, 0, 1))\n",
    "        yield img_name, np.asarray([img], dtype=np.float32) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(input_string):\n",
    "    return [(len(list(g)), k) for k,g in groupby(input_string)]\n",
    "\n",
    "def run_length(label_vec):\n",
    "    encode_list = encode(label_vec)\n",
    "    index = 1\n",
    "    class_dict = {}\n",
    "    for i in encode_list:\n",
    "        if i[1] != category_num-1:\n",
    "            if i[1] not in class_dict.keys():\n",
    "                class_dict[i[1]] = []\n",
    "            class_dict[i[1]] = class_dict[i[1]] + [index, i[0]]\n",
    "        index += i[0]\n",
    "    return class_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class double_conv(nn.Module):\n",
    "    '''(conv => BN => ReLU) * 2'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class inconv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(inconv, self).__init__()\n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(down, self).__init__()\n",
    "        self.mpconv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            double_conv(in_ch, out_ch)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mpconv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, bilinear=True):\n",
    "        super(up, self).__init__()\n",
    "\n",
    "        #  would be a nice idea if the upsampling could be learned too,\n",
    "        #  but my machine do not have enough memory to handle all those weights\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_ch//2, in_ch//2, 2, stride=2)\n",
    "\n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        diffX = x1.size()[2] - x2.size()[2]\n",
    "        diffY = x1.size()[3] - x2.size()[3]\n",
    "        x2 = F.pad(x2, (diffX // 2, int(diffX / 2),\n",
    "                        diffY // 2, int(diffY / 2)))\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class outconv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(outconv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(UNet, self).__init__()\n",
    "        self.inc = inconv(n_channels, 64)\n",
    "        self.down1 = down(64, 128)\n",
    "        self.down2 = down(128, 256)\n",
    "        self.down3 = down(256, 512)\n",
    "        self.down4 = down(512, 512)\n",
    "        self.up1 = up(1024, 256)\n",
    "        self.up2 = up(512, 128)\n",
    "        self.up3 = up(256, 64)\n",
    "        self.up4 = up(128, 64)\n",
    "        self.outc = outconv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        x = self.outc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(331213, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83353"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "333415 // 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "      <th>ClassId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83348</th>\n",
       "      <td>404b0d1b58a1af0841e1e46f975118eb.jpg</td>\n",
       "      <td>337743 2 338739 6 339735 10 340732 13 341728 1...</td>\n",
       "      <td>1000</td>\n",
       "      <td>667</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83349</th>\n",
       "      <td>404b0d1b58a1af0841e1e46f975118eb.jpg</td>\n",
       "      <td>235561 2 236558 5 237554 9 238551 13 239549 15...</td>\n",
       "      <td>1000</td>\n",
       "      <td>667</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83350</th>\n",
       "      <td>404b0d1b58a1af0841e1e46f975118eb.jpg</td>\n",
       "      <td>219425 10 220411 30 221398 50 222385 68 223374...</td>\n",
       "      <td>1000</td>\n",
       "      <td>667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83351</th>\n",
       "      <td>404b0d1b58a1af0841e1e46f975118eb.jpg</td>\n",
       "      <td>298226 2 299225 7 300225 11 301225 14 302224 1...</td>\n",
       "      <td>1000</td>\n",
       "      <td>667</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83352</th>\n",
       "      <td>404b0d1b58a1af0841e1e46f975118eb.jpg</td>\n",
       "      <td>379364 12 380342 1 380352 27 381340 4 381351 3...</td>\n",
       "      <td>1000</td>\n",
       "      <td>667</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83353</th>\n",
       "      <td>404b0d1b58a1af0841e1e46f975118eb.jpg</td>\n",
       "      <td>219425 10 220411 30 221398 50 222385 68 223374...</td>\n",
       "      <td>1000</td>\n",
       "      <td>667</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    ImageId  \\\n",
       "83348  404b0d1b58a1af0841e1e46f975118eb.jpg   \n",
       "83349  404b0d1b58a1af0841e1e46f975118eb.jpg   \n",
       "83350  404b0d1b58a1af0841e1e46f975118eb.jpg   \n",
       "83351  404b0d1b58a1af0841e1e46f975118eb.jpg   \n",
       "83352  404b0d1b58a1af0841e1e46f975118eb.jpg   \n",
       "83353  404b0d1b58a1af0841e1e46f975118eb.jpg   \n",
       "\n",
       "                                           EncodedPixels  Height  Width  \\\n",
       "83348  337743 2 338739 6 339735 10 340732 13 341728 1...    1000    667   \n",
       "83349  235561 2 236558 5 237554 9 238551 13 239549 15...    1000    667   \n",
       "83350  219425 10 220411 30 221398 50 222385 68 223374...    1000    667   \n",
       "83351  298226 2 299225 7 300225 11 301225 14 302224 1...    1000    667   \n",
       "83352  379364 12 380342 1 380352 27 381340 4 381351 3...    1000    667   \n",
       "83353  219425 10 220411 30 221398 50 222385 68 223374...    1000    667   \n",
       "\n",
       "      ClassId  \n",
       "83348      22  \n",
       "83349       8  \n",
       "83350       0  \n",
       "83351      28  \n",
       "83352      31  \n",
       "83353      31  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[83348:83354, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "      <th>ClassId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73350</th>\n",
       "      <td>3892703cf1e7f6a3cc1892fcb3daedae.jpg</td>\n",
       "      <td>85434 2 88642 6 91851 9 95059 14 98268 17 1014...</td>\n",
       "      <td>3211</td>\n",
       "      <td>2141</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73351</th>\n",
       "      <td>3892703cf1e7f6a3cc1892fcb3daedae.jpg</td>\n",
       "      <td>82220 2 85428 6 88637 9 91846 13 95055 16 9826...</td>\n",
       "      <td>3211</td>\n",
       "      <td>2141</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73352</th>\n",
       "      <td>3893868714043964534a6cdbaf1f0d75.jpg</td>\n",
       "      <td>7536415 56 7542028 60 7547642 62 7553255 65 75...</td>\n",
       "      <td>5616</td>\n",
       "      <td>3744</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73353</th>\n",
       "      <td>3893868714043964534a6cdbaf1f0d75.jpg</td>\n",
       "      <td>12534531 11 12540144 33 12545757 55 12551369 6...</td>\n",
       "      <td>5616</td>\n",
       "      <td>3744</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    ImageId  \\\n",
       "73350  3892703cf1e7f6a3cc1892fcb3daedae.jpg   \n",
       "73351  3892703cf1e7f6a3cc1892fcb3daedae.jpg   \n",
       "73352  3893868714043964534a6cdbaf1f0d75.jpg   \n",
       "73353  3893868714043964534a6cdbaf1f0d75.jpg   \n",
       "\n",
       "                                           EncodedPixels  Height  Width  \\\n",
       "73350  85434 2 88642 6 91851 9 95059 14 98268 17 1014...    3211   2141   \n",
       "73351  82220 2 85428 6 88637 9 91846 13 95055 16 9826...    3211   2141   \n",
       "73352  7536415 56 7542028 60 7547642 62 7553255 65 75...    5616   3744   \n",
       "73353  12534531 11 12540144 33 12545757 55 12551369 6...    5616   3744   \n",
       "\n",
       "      ClassId  \n",
       "73350      31  \n",
       "73351       1  \n",
       "73352      23  \n",
       "73353      23  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[73350:73354, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, use about 25% data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = UNet(n_channels=3, n_classes=category_num).to(device)\n",
    "\n",
    "# optimizer = optim.SGD(\n",
    "#     net.parameters(),\n",
    "#     lr=0.01,\n",
    "#     momentum=0.9,\n",
    "#     weight_decay=0.0005\n",
    "# )\n",
    "optimizer = optim.Adam(net.parameters(),\n",
    "                       lr=0.01\n",
    "                      )\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('w.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-99-3401c2a0f8ae>:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for iteration, (X_trn, Y_trn) in enumerate(tqdm(train_generator(train_df.iloc[:val_sta, :], batch_size))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c859278029a3466c9fa23f09ff1ef390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss in 01epoch  /    0iter:    0.48244777\n",
      "train loss in 01epoch  /  100iter:    0.4188875 \n",
      "train loss in 01epoch  /  200iter:    0.38496849\n",
      "train loss in 01epoch  /  300iter:    0.36789627\n",
      "train loss in 01epoch  /  400iter:    0.35921227\n",
      "train loss in 01epoch  /  500iter:    0.35193099\n",
      "train loss in 01epoch  /  600iter:    0.34690535\n",
      "train loss in 01epoch  /  700iter:    0.34382413\n",
      "train loss in 01epoch  /  800iter:    0.33933571\n",
      "train loss in 01epoch  /  900iter:    0.33441083\n",
      "train loss in 01epoch  / 1000iter:    0.33221865\n",
      "train loss in 01epoch  / 1100iter:    0.32820888\n",
      "train loss in 01epoch  / 1200iter:    0.32407237\n",
      "\n",
      "train 1epoch loss(1251iteration):    0.32274931\n",
      "valid 1epoch loss(1251iteration):           0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86745128f3a84127873980f11af9434f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss in 02epoch  /    0iter:    0.39506108\n",
      "train loss in 02epoch  /  100iter:    0.27711976\n",
      "train loss in 02epoch  /  200iter:    0.27868444\n",
      "train loss in 02epoch  /  300iter:    0.27533482\n",
      "train loss in 02epoch  /  400iter:    0.27379406\n",
      "train loss in 02epoch  /  500iter:    0.27165127\n",
      "train loss in 02epoch  /  600iter:    0.27052967\n",
      "train loss in 02epoch  /  700iter:    0.27062766\n",
      "train loss in 02epoch  /  800iter:    0.26884806\n",
      "train loss in 02epoch  /  900iter:    0.26586354\n",
      "train loss in 02epoch  / 1000iter:    0.26555444\n",
      "train loss in 02epoch  / 1100iter:    0.2635777 \n",
      "train loss in 02epoch  / 1200iter:    0.26072175\n",
      "\n",
      "train 2epoch loss(1251iteration):    0.26004256\n",
      "valid 2epoch loss(1251iteration):           0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559a94722c2b46cf9d1096386dcb1a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss in 03epoch  /    0iter:    0.33171886\n",
      "train loss in 03epoch  /  100iter:    0.23228856\n",
      "train loss in 03epoch  /  200iter:    0.23762929\n",
      "train loss in 03epoch  /  300iter:    0.23545219\n",
      "train loss in 03epoch  /  400iter:    0.23394902\n",
      "train loss in 03epoch  /  500iter:    0.23240549\n",
      "train loss in 03epoch  /  600iter:    0.23156812\n",
      "train loss in 03epoch  /  700iter:    0.23335491\n",
      "train loss in 03epoch  /  800iter:    0.23234318\n",
      "train loss in 03epoch  /  900iter:    0.23014837\n",
      "train loss in 03epoch  / 1000iter:    0.22973617\n",
      "train loss in 03epoch  / 1100iter:    0.22868745\n",
      "train loss in 03epoch  / 1200iter:    0.2265994 \n",
      "\n",
      "train 3epoch loss(1251iteration):    0.22628324\n",
      "valid 3epoch loss(1251iteration):           0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "377b4aedb4144ab0ac86b448679835b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss in 04epoch  /    0iter:    0.28241542\n",
      "train loss in 04epoch  /  100iter:    0.20642415\n",
      "train loss in 04epoch  /  200iter:    0.21276686\n",
      "train loss in 04epoch  /  300iter:    0.21101318\n",
      "train loss in 04epoch  /  400iter:    0.2088131 \n",
      "train loss in 04epoch  /  500iter:    0.20805539\n",
      "train loss in 04epoch  /  600iter:    0.2067694 \n",
      "train loss in 04epoch  /  700iter:    0.20816159\n",
      "train loss in 04epoch  /  800iter:    0.20830049\n",
      "train loss in 04epoch  /  900iter:    0.20660592\n",
      "train loss in 04epoch  / 1000iter:    0.20627322\n",
      "train loss in 04epoch  / 1100iter:    0.20572647\n",
      "train loss in 04epoch  / 1200iter:    0.20403844\n",
      "\n",
      "train 4epoch loss(1251iteration):    0.20390807\n",
      "valid 4epoch loss(1251iteration):           0.0\n"
     ]
    }
   ],
   "source": [
    "val_sta = 73352\n",
    "val_end = 83351\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "for epoch in range(epoch_num):\n",
    "    epoch_trn_loss = 0\n",
    "    train_len = 0\n",
    "    net.train()\n",
    "    for iteration, (X_trn, Y_trn) in enumerate(tqdm(train_generator(train_df.iloc[:val_sta, :], batch_size))):\n",
    "        Y_trn[Y_trn == 1] = 0\n",
    "        Y_trn[Y_trn != 0] = 1\n",
    "        X = torch.tensor(X_trn, dtype=torch.float32).to(device)\n",
    "        Y = torch.tensor(Y_trn, dtype=torch.long).to(device)\n",
    "        train_len += len(X)\n",
    "        \n",
    "        #Y_flat = Y.view(-1)\n",
    "        mask_pred = net(X)\n",
    "        #mask_prob = torch.softmax(mask_pred, dim=1)\n",
    "        #mask_prob_flat = mask_prob.view(-1)\n",
    "        loss = criterion(mask_pred, Y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_trn_loss += loss.item()\n",
    "        \n",
    "        if iteration % 100 == 0:\n",
    "            print(\"train loss in {:0>2}epoch  /{:>5}iter:    {:<10.8}\".format(epoch+1, iteration, epoch_trn_loss/(iteration+1)))\n",
    "        \n",
    "    train_loss.append(epoch_trn_loss/(iteration+1))\n",
    "    print(\"train {}epoch loss({}iteration):    {:10.8}\".format(epoch+1, iteration, train_loss[-1]))\n",
    "    \n",
    "    epoch_val_loss = 0\n",
    "    val_len = 0\n",
    "    net.eval()\n",
    "#     for iteration, (X_val, Y_val) in enumerate(tqdm(train_generator(train_df.iloc[val_sta:val_end, :], batch_size))):\n",
    "#         Y_val[Y_val == 1] = 0\n",
    "#         Y_val[Y_val != 0] = 1\n",
    "#         X = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "#         Y = torch.tensor(Y_val, dtype=torch.long).to(device)\n",
    "#         val_len += len(X)\n",
    "        \n",
    "#         #Y_flat = Y.view(-1)\n",
    "        \n",
    "#         mask_pred = net(X)\n",
    "#         #mask_prob = torch.softmax(mask_pred, dim=1)\n",
    "#         #mask_prob_flat = mask_prob.view(-1)\n",
    "#         loss = criterion(mask_pred, Y)\n",
    "#         epoch_val_loss += loss.item()\n",
    "        \n",
    "#         if iteration % 100 == 0:\n",
    "#             print(\"valid loss in {:0>2}epoch  /{:>5}iter:    {:<10.8}\".format(epoch+1, iteration, epoch_val_loss/(iteration+1)))\n",
    "        \n",
    "    valid_loss.append(epoch_val_loss/(iteration+1))\n",
    "    print(\"valid {}epoch loss({}iteration):    {:10.8}\".format(epoch+1, iteration, valid_loss[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(list(range(epoch_num)), train_loss, color='green')\n",
    "#plt.plot(list(range(epoch_num)), valid_loss, color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'w.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidea-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with dice loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMOOTH = 1e-6\n",
    "\n",
    "def iou_pytorch(outputs: torch.Tensor, labels: torch.Tensor):\n",
    "    # You can comment out this line if you are passing tensors of equal shape\n",
    "    # But if you are passing output from UNet or something it will most probably\n",
    "    # be with the BATCH x H x W shape\n",
    "    \n",
    "    intersection = (outputs & labels).float().sum((1, 2))  # Will be zero if Truth=0 or Prediction=0\n",
    "    union = (outputs | labels).float().sum((1, 2))         # Will be zzero if both are 0\n",
    "    iou = (intersection) / (union + SMOOTH)  # We smooth our devision to avoid 0/0\n",
    "    print(iou)\n",
    "    thresholded = torch.clamp(20 * (iou - 0.5), 0, 10).ceil() / 10  # This is equal to comparing with thresolds\n",
    "    \n",
    "    return thresholded  # Or thresholded.mean() if you are interested in average across the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \n",
    "#         #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "#         inputs = torch.sigmoid(inputs)       \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "        return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = UNet(n_channels=3, n_classes=1).to(device)\n",
    "\n",
    "# optimizer = optim.SGD(\n",
    "#     net.parameters(),\n",
    "#     lr=0.01,\n",
    "#     momentum=0.9,\n",
    "#     weight_decay=0.0005\n",
    "# )\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "criterion = DiceLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sta = 73352\n",
    "val_end = 83351"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-48-38188dd63974>:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for iteration, (X_trn, Y_trn) in enumerate(tqdm(train_generator(train_df.iloc[:val_sta, :], batch_size))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898a42497db143af87b8ab575bb6d88d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss in 01epoch  /    0iter:    0.70920992\n",
      "train loss in 01epoch  /  100iter:    0.71393511\n",
      "train loss in 01epoch  /  200iter:    0.70716161\n",
      "train loss in 01epoch  /  300iter:    0.70443006\n",
      "train loss in 01epoch  /  400iter:    0.70049575\n",
      "train loss in 01epoch  /  500iter:    0.69877072\n",
      "train loss in 01epoch  /  600iter:    0.69675661\n",
      "train loss in 01epoch  /  700iter:    0.69471446\n",
      "train loss in 01epoch  /  800iter:    0.69481793\n",
      "train loss in 01epoch  /  900iter:    0.69484142\n",
      "train loss in 01epoch  / 1000iter:    0.69321792\n",
      "train loss in 01epoch  / 1100iter:    0.69369678\n",
      "train loss in 01epoch  / 1200iter:    0.69343167\n",
      "\n",
      "train 1epoch loss(1251iteration):    0.69287003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e25c3a60dfca4798b6f1a2c2db4cbad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss in 02epoch  /    0iter:    0.6727227 \n",
      "train loss in 02epoch  /  100iter:    0.68977379\n",
      "train loss in 02epoch  /  200iter:    0.68882628\n",
      "train loss in 02epoch  /  300iter:    0.68930498\n",
      "train loss in 02epoch  /  400iter:    0.6866619 \n",
      "train loss in 02epoch  /  500iter:    0.68554328\n",
      "train loss in 02epoch  /  600iter:    0.68395945\n",
      "train loss in 02epoch  /  700iter:    0.68207069\n",
      "train loss in 02epoch  /  800iter:    0.68231361\n",
      "train loss in 02epoch  /  900iter:    0.68261587\n",
      "train loss in 02epoch  / 1000iter:    0.68129607\n",
      "train loss in 02epoch  / 1100iter:    0.68204127\n",
      "train loss in 02epoch  / 1200iter:    0.68200697\n",
      "\n",
      "train 2epoch loss(1251iteration):     0.6815725\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aad911c6a7a04f5f8a171d868263d40a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss in 03epoch  /    0iter:    0.65921414\n",
      "train loss in 03epoch  /  100iter:    0.68252663\n",
      "train loss in 03epoch  /  200iter:    0.68238483\n",
      "train loss in 03epoch  /  300iter:    0.68263729\n",
      "train loss in 03epoch  /  400iter:    0.67997336\n",
      "train loss in 03epoch  /  500iter:    0.67913608\n",
      "train loss in 03epoch  /  600iter:    0.67780209\n",
      "train loss in 03epoch  /  700iter:    0.6760731 \n",
      "train loss in 03epoch  /  800iter:    0.67655976\n",
      "train loss in 03epoch  /  900iter:    0.67705625\n",
      "train loss in 03epoch  / 1000iter:    0.67577872\n",
      "train loss in 03epoch  / 1100iter:    0.67667834\n",
      "train loss in 03epoch  / 1200iter:    0.67674577\n",
      "\n",
      "train 3epoch loss(1251iteration):    0.67634858\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b75b1db5aaa4902b253e95ad98dd301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss in 04epoch  /    0iter:    0.64770871\n",
      "train loss in 04epoch  /  100iter:    0.68082815\n",
      "train loss in 04epoch  /  200iter:    0.68015338\n",
      "train loss in 04epoch  /  300iter:    0.68024763\n",
      "train loss in 04epoch  /  400iter:    0.67748833\n",
      "train loss in 04epoch  /  500iter:    0.67666279\n",
      "train loss in 04epoch  /  600iter:    0.67521772\n",
      "train loss in 04epoch  /  700iter:    0.6735155 \n",
      "train loss in 04epoch  /  800iter:    0.67398567\n",
      "train loss in 04epoch  /  900iter:    0.67451331\n",
      "train loss in 04epoch  / 1000iter:    0.67326329\n",
      "train loss in 04epoch  / 1100iter:    0.67421259\n",
      "train loss in 04epoch  / 1200iter:    0.67425571\n",
      "\n",
      "train 4epoch loss(1251iteration):    0.67387957\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "valid_loss = []\n",
    "for epoch in range(epoch_num):\n",
    "    epoch_trn_loss = 0\n",
    "    train_len = 0\n",
    "    net.train()\n",
    "    for iteration, (X_trn, Y_trn) in enumerate(tqdm(train_generator(train_df.iloc[:val_sta, :], batch_size))):\n",
    "        Y_trn[Y_trn == 1] = 0\n",
    "        Y_trn[Y_trn != 0] = 1\n",
    "        X = torch.tensor(X_trn, dtype = torch.float32).to(device)\n",
    "        Y = torch.tensor(Y_trn, dtype = torch.float32).to(device)\n",
    "        train_len += len(X)\n",
    "        \n",
    "        mask_pred = torch.sigmoid(net(X))\n",
    "        loss = criterion(mask_pred, Y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_trn_loss += loss.item()\n",
    "        \n",
    "        if iteration % 100 == 0:\n",
    "            print(\"train loss in {:0>2}epoch  /{:>5}iter:    {:<10.8}\".format(epoch+1, iteration, epoch_trn_loss/(iteration+1)))\n",
    "        \n",
    "    train_loss.append(epoch_trn_loss/(iteration+1))\n",
    "    print(\"train {}epoch loss({}iteration):    {:10.8}\".format(epoch+1, iteration, train_loss[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'w_unet_4_sig.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('w_unet_4.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_val_loss = 0\n",
    "val_len = 0\n",
    "net.eval()\n",
    "for iteration, (X_val, Y_val) in enumerate(tqdm(train_generator(train_df.iloc[val_sta:val_end, :], batch_size))):\n",
    "        Y_val[Y_val == 1] = 0\n",
    "        Y_val[Y_val != 0] = 1\n",
    "        X = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "        Y = torch.tensor(Y_val, dtype=torch.float32).to(device)\n",
    "        val_len += len(X)\n",
    "        \n",
    "        #Y_flat = Y.view(-1)\n",
    "        \n",
    "        mask_pred = net(X)\n",
    "        #mask_prob = torch.softmax(mask_pred, dim=1)\n",
    "        #mask_prob_flat = mask_prob.view(-1)\n",
    "        loss = criterion(mask_pred, Y)\n",
    "        epoch_val_loss += loss.item()\n",
    "        \n",
    "        if iteration % 100 == 0:\n",
    "            print(\"valid loss / {:<10.8}\".format(epoch_val_loss/(iteration+1)))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank you for watching!\n",
    "Please tell me when I make mistakes in program and English.  \n",
    "I hope this kernel will help.  \n",
    "If you think this kernel is useful, please upvote. If you do, I feel happy and get enough sleep.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(model):\n",
    "    for iteration, (X_trn, Y) in enumerate(tqdm(train_generator(train_df.iloc[:val_sta, :], batch_size))):\n",
    "        X = torch.tensor(X_trn, dtype=torch.float32).to(device)\n",
    "        break\n",
    "    i = np.random.randit(batch_size)\n",
    "    mask = Y[i]\n",
    "    img = X[i]\n",
    "    pred = torch.sigmoid(model(X)).detach().cpu().numpy()[i] > 0.5\n",
    "    masked_img = img.copy()\n",
    "    masked_pred = img.copy()\n",
    "    \n",
    "    for lay in range(3):\n",
    "        masked_img[lay] *= mask\n",
    "        masked_pred[lay] *= pred\n",
    "    images = [img, mask, masked_img, pred, mask_pred]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 5)\n",
    "    for ax, images in zip(axes.flatten(), images):\n",
    "        ax.imshow()\n",
    "        \n",
    "    fig.suptitle('Horizontally stacked subplots')\n",
    "    ax1.plot(x, y)\n",
    "    ax2.plot(x, -y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-51-0221ca91921e>:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for iteration, (X_trn, Y_trn) in enumerate(tqdm(train_generator(train_df.iloc[:val_sta, :], batch_size))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab819b9bfe247768acbc47d1bfcd174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = X[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 224, 224)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.sigmoid(net(X)).detach().cpu().numpy()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f86442c15b0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[125] > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f86444539a0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
